Silhou<-NULL
for (k in 2:Kmax){
aux<-silhouette(reskmeanscl[,k-1], daisy(wine_quant))
Silhou<-c(Silhou,mean(aux[,3]))
}
df<-data.frame(K=2:Kmax,Silhouette=Silhou)
ggplot(df,aes(x=K,y=Silhouette))+
geom_point()+
geom_line()+theme(legend.position = "bottom")
aux<-silhouette(reskmeanscl[,3], daisy(wine_quant))
fviz_silhouette(aux)+theme(plot.title = element_text(size =9))
rm(df,Silhou,aux)
resPAM<-pam(wine_quant, 3, metric = "euclidean")
resPAM$medoids
resPAM$id.med
fviz_cluster(resPAM,data=wine[,-c(1,2)],ellipse.type="norm",labelsize=8,geom=c("point"))+ggtitle("")
fviz_pca_ind(res.acp,col.ind=as.factor(resPAM$clustering),geom = c("point"),axes=c(1,2))
adjustedRandIndex(resPAM$clustering, wine$Qualite)
adjustedRandIndex(resPAM$clustering, wine$Type)
adjustedRandIndex(resPAM$clustering, reskmeans$cluster)
table(resPAM$clustering, reskmeans$cluster)
Kmax<-15
resPAMcl<-matrix(0,nrow=nrow(wine),ncol=Kmax-1)
Silhou<-NULL
for (k in 2:Kmax){
resaux<-pam(wine_quant, k, metric = "euclidean")
resPAMcl[,k-1]<-resaux$clustering
aux<-silhouette(resPAMcl[,k-1], daisy(wine[,-c(1,2)]))
Silhou<-c(Silhou,mean(aux[,3]))
}
df<-data.frame(K=2:Kmax,Silhouette=Silhou)
ggplot(df,aes(x=K,y=Silhouette))+
geom_point()+
geom_line()+theme(legend.position = "bottom")
aux<-silhouette(resPAMcl[,1], daisy(wine[,-c(1:2)]))
fviz_silhouette(aux)+theme(plot.title = element_text(size =9))
### Présentation
Avec les algorithmes de clustering précédents (Kmeans, PAM) nous obtenons une classification "dure" au sens que chaque individu ne peut appartenir qu'à une seule classe et chaque individu participe avec le même poids à la construction des classes. Une classification dure $\mathcal{P}_K=\{\mathcal{C}_1,\ldots,\mathcal{C}_K\}$ peut se traduire en une matrice $Z=(z_{ik})_{\underset{1\leq k \leq K}{1\leq i \leq n}}$ avec $z_{ik}=1$ si $i\in\mathcal{C}_k$ et 0 sinon. Dans cette section, nous allons nous intéresser à une adaptation de l'algorithme des Kmeans, appelée *fuzzy c-means*. L'idée est de retourner une classification *fuzzy* c'est-à-dire une matrice $W=(\omega_{ik})_{\underset{1\leq k \leq K}{1\leq i \leq n}}$ avec $\forall i,\ k,\ \omega_{ik}\geq 0$ et $\forall i,\ \underset{k=1}{\stackrel{K}{\sum}} \omega_{ik}=1$. On donne ainsi plutôt un poids $\omega_{ik}$ que l'individu $i$ appartienne à la classe $\mathcal{C}_k$.
Kmax<-15
resPAMcl<-matrix(0,nrow=nrow(wine),ncol=Kmax-1)
Silhou<-NULL
for (k in 2:Kmax){
resaux<-pam(wine_quant, k, metric = "euclidean")
resPAMcl[,k-1]<-resaux$clustering
aux<-silhouette(resPAMcl[,k-1], daisy(wine_quant))
Silhou<-c(Silhou,mean(aux[,3]))
}
df<-data.frame(K=2:Kmax,Silhouette=Silhou)
ggplot(df,aes(x=K,y=Silhouette))+
geom_point()+
geom_line()+theme(legend.position = "bottom")
aux<-silhouette(resPAMcl[,1], daisy(wine[,-c(1:2)]))
fviz_silhouette(aux)+theme(plot.title = element_text(size =9))
Kmax<-15
resPAMcl<-matrix(0,nrow=nrow(wine),ncol=Kmax-1)
Silhou<-NULL
for (k in 2:Kmax){
resaux<-pam(wine_quant, k, metric = "euclidean")
resPAMcl[,k-1]<-resaux$clustering
aux<-silhouette(resPAMcl[,k-1], daisy(wine_quant))
Silhou<-c(Silhou,mean(aux[,3]))
}
df<-data.frame(K=2:Kmax,Silhouette=Silhou)
ggplot(df,aes(x=K,y=Silhouette))+
geom_point()+
geom_line()+theme(legend.position = "bottom")
aux<-silhouette(resPAMcl[,1], daisy(wine_quant))
fviz_silhouette(aux)+theme(plot.title = element_text(size =9))
help(fcm)
# A COMPLETER
library(ppclust)
resfcm<-fcm(wine_quant, 3)
# A COMPLETER
library(ppclust)
resfcm<-fcm(wine_quant, 3, m=2)
table(apply(resfcm$u, 1, which.max))
# A COMPLETER
library(ppclust)
resfcm<-fcm(wine_quant, 3, m=2)
resfcm$u
table(apply(resfcm$u, 1, which.max))
# A COMPLETER
library(ppclust)
resfcm<-fcm(wine_quant, 3, m=2)
table(apply(resfcm$u, 1, which.max))
# A COMPLETER
library(ppclust)
resfcm<-fcm(wine_quant, 3, m=2)
table(apply(resfcm$u, 1, which.max)) # on sélectionne le poids le plus grand
boxplot(apply(resfcm$u, 1, max))~apply(resfcm$u, 1, which.max)
# A COMPLETER
library(ppclust)
resfcm<-fcm(wine_quant, 3, m=2)
table(apply(resfcm$u, 1, which.max)) # on sélectionne le poids le plus grand
boxplot(apply(resfcm$u, 1, max)~apply(resfcm$u, 1, which.max))
# A COMPLETER
library(ppclust)
resfcm<-fcm(wine_quant, 3, m=2)
table(apply(resfcm$u, 1, which.max)) # on sélectionne le poids le plus grand
boxplot(apply(resfcm$u, 1, max)~apply(resfcm$u, 1, which.max))
#on attribue l'indiidu à la classe où il a le poids le plus fort
# A COMPLETER
fviz_pca_ind(resacp,axes=c(1,2),geom=c("point"),col.ind=apply(resfcm$u, 1, which.max))+
scale_color_gradient2(low="white", mid="blue",high="red", midpoint=0.8, space = "Lab")
# A COMPLETER
fviz_pca_ind(res.acp,axes=c(1,2),geom=c("point"),col.ind=apply(resfcm$u, 1, which.max))+
scale_color_gradient2(low="white", mid="blue",high="red", midpoint=0.8, space = "Lab")
# A COMPLETER
fviz_pca_ind(res.acp,axes=c(1,2),geom=c("point"),col.ind=apply(resfcm$u, 1, max))+
scale_color_gradient2(low="white", mid="blue",high="red", midpoint=0.8, space = "Lab")
res.acp = PCA(wine, scale.unit = TRUE, ncp = 6, quali.sup = 1:2, graph = TRUE, axes = c(1,2))
fviz_pca_ind(res.acp, axes=c(1,2), geom=c("point"), habillage = wine$Type)
fviz_pca_ind(res.acp, geom=c("point"), habillage = wine$Qualite)
fviz_eig(res.acp)
res.acp = PCA(wine, scale.unit = TRUE, ncp = ncol(6), quali.sup = 1:2, graph = TRUE, axes = c(1,2))
fviz_pca_ind(res.acp, axes=c(1,2), geom=c("point"), habillage = wine$Type)
fviz_pca_ind(res.acp, geom=c("point"), habillage = wine$Qualite)
fviz_eig(res.acp)
library(knitr)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=FALSE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE,
class.source="badCode")
opts_knit$set(width=75)
library(mclust)
library(cluster)
library(factoextra)
library(FactoMineR)
library(ppclust)
library(reticulate)
library(ggplot2)
library(reshape)
library(corrplot)
library(gridExtra)
library(circlize)
library(viridis)
library(reshape2)
library(klaR)
str(wine)
res.acp = PCA(wine, scale.unit = TRUE, ncp = ncol(6), quali.sup = 1:2, graph = TRUE, axes = c(1,2))
fviz_pca_ind(res.acp, axes=c(1,2), geom=c("point"), habillage = wine$Type)
fviz_pca_ind(res.acp, geom=c("point"), habillage = wine$Qualite)
fviz_eig(res.acp)
fviz_pca_ind(res.acp, col.ind = as.factor(reskmeans$cluster), geom=c("point"), axes = c(1,2))
reskmeans
# J indice des variables
# Data = jeu de données
# clust = clustering étudié
# output : graphe par variable dans J donnant la répartition des modalités de J par classe de clust
barplotClus <- function(clust, Data, J) {
aux.long.p <- heatm(clust, Data, J)$freq
# ux<-unique(aux.long.p$variable)
for (j in J) {
p <- ggplot(aux.long.p[which(aux.long.p$variable == colnames(Data)[j]), ],
aes(x = clust, y = perc, fill = value)) + geom_bar(stat = "identity")+
labs(fill = colnames(Data)[j])
print(p)
}
}
heatm <- function(clust, Data, J) {
library(dplyr)
Dataaux <- data.frame(id.s = c(1:nrow(Data)), Data)
aux <- cbind(Dataaux, clust)
aux.long <- melt(data.frame(lapply(aux, as.character)), stringsAsFactors = FALSE,
id = c("id.s", "clust"), factorsAsStrings = T)
# Effectifs
aux.long.q <- aux.long %>%
group_by(clust, variable, value) %>%
mutate(count = n_distinct(id.s)) %>%
distinct(clust, variable, value, count)
# avec fréquences
aux.long.p <- aux.long.q %>%
group_by(clust, variable) %>%
mutate(perc = count/sum(count)) %>%
arrange(clust)
Lev <- NULL
for (j in 1:ncol(Data)) Lev <- c(Lev, levels(Data[, j]))
Jaux <- NULL
for (j in 1:length(J)) {
Jaux <- c(Jaux, which(aux.long.p$variable == colnames(Data)[J[j]]))
}
gaux <- ggplot(aux.long.p[Jaux, ], aes(x = clust, y = value)) + geom_tile(aes(fill = perc)) +
scale_fill_gradient2(low = "white", mid = "blue", high = "red") + theme_minimal()
return(list(gaux = gaux, eff = aux.long.q, freq = aux.long.p))
}
fviz_pca_ind(res.acp,axes=c(1,2),geom=c("point"),col.ind=apply(resfcm$u, 1, max))+
scale_color_gradient2(low="white", mid="blue",high="red", midpoint=0.8, space = "Lab")
zoo<- read.table("zoo.txt")
# A COMPLETER
zoo<- read.table("zoo-dataTP.txt")
# A COMPLETER
zoo<- read.table("zoo-dataTP.txt")
str(zoo)
res.mca<-MCA(zoo)
# A COMPLETER
res.mca<-MCA(zoo, quali.sup = 7)
# A COMPLETER
zoo<- read.table("zoo-dataTP.txt")
head(zoo)
zoo<- read.table("zoo-dataTP.txt")
head(zoo)
zoo = as.factor(zoo)
res.mca<-MCA(zoo)
# A COMPLETER
zoo<- read.table("zoo-dataTP.txt")
head(zoo)
zoo = as.factor(zoo)
str(zoo)
zoo<- read.table("zoo-dataTP.txt")
zoo<- read.table("zoo-dataTP.txt")
for (j in 1:ncol(zoo)) {
zoo[,j] = as.factor(zoo[,j])
}
res.mca<-MCA(zoo)
# A COMPLETER
res.mca<-MCA(zoo, quali.sup = 7)
# A COMPLETER
res.mca<-MCA(zoo)
# A COMPLETER
library(knitr)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=FALSE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE,
class.source="badCode")
opts_knit$set(width=75)
library(mclust)
library(cluster)
library(factoextra)
library(FactoMineR)
library(ppclust)
library(reticulate)
library(ggplot2)
library(reshape)
library(corrplot)
library(gridExtra)
library(circlize)
library(viridis)
library(reshape2)
library(klaR)
wine <-read.table("wine.txt")
str(wine)
wine$Qualite <- as.factor(wine$Qualite)
wine$Type <- factor(wine$Type)
levels(wine$Type) = c("Rouge", "Blanc")
str(wine)
table(wine$Type)
boxplot(wine)
pairs(wine)
corrplot(cor(wine[,3:8]), method = "ellipse")
ggplot(wine, aes(x=Type))+ geom_bar() + ylab("")+ ggtitle("Effectifs")
ggplot(wine, aes(x=Qualite))+ geom_bar() + ylab("")+ ggtitle("Effectifs")
res.acp = PCA(wine, scale.unit = TRUE, ncp = ncol(6), quali.sup = 1:2, graph = TRUE, axes = c(1,2))
fviz_pca_ind(res.acp, axes=c(1,2), geom=c("point"), habillage = wine$Type)
fviz_pca_ind(res.acp, geom=c("point"), habillage = wine$Qualite)
fviz_eig(res.acp)
wine_quant = wine[,3:8]
wine_quant = scale(wine_quant, center = T, scale = T)
help(kmeans)
reskmeans<-kmeans(wine_quant, centers = 3)
help(kmeans)
reskmeans<-kmeans(wine_quant, centers = 3)
reskmeans
help(kmeans)
reskmeans<-kmeans(wine_quant, centers = 3)
reskmeans$centers
fviz_cluster(reskmeans, data = wine_quant, ellipse.type = "norm", labelsize = 8, geom = c("point"))+ggtitle("")
table(reskmeans$cluster)
help(kmeans)
reskmeans<-kmeans(wine_quant, centers = 3)
reskmeans
reskmeans$centers
library(knitr)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=FALSE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE,
class.source="badCode")
opts_knit$set(width=75)
## Pour faire le TP
library(mclust)
library(Rmixmod)
library(ggplot2)
library(gridExtra)
library(FactoMineR)
library(factoextra)
library(reshape2)
library(circlize)
library(viridis)
library(mclust)
data(Baudry_etal_2010_JCGS_examples)
Data<-ex4.1
ggplot(Data,aes(x=X1,y=X2))+geom_point()
resICL<-mclustICL(Data, G=2:10)
summary(resICL)
resICL<-Mclust(Data, G=6, modelNames = "EEV")
aux = data.frame(label=paste("Cl", resICL$classification, sep = ""), proba = apply(resICL$z, 1, max))
# Boxplot des probabilités a posteriori maximales
h1 = ggplot(aux,aes(x=label, y=proba))+ geom_boxplot()
# Visualisation du clustering
h2 = fviz_cluster(resICL, data = Data, ellipse.type="norm", geom = "point") +ggtitle("")+theme(legend.position = "none")
grid.arrange(h1,h2,ncol=2)
# Effectifs par classe
wine<-read.table("wine.txt",header=T)
wine$Qualite = as.factor(wine$Qualite)
wine$Type = factor(wine$Type, labels = c("blanc", "rouge"))
wineinit<-wine
wine[,-c(1,2)]<-scale(wine[,-c(1,2)],center=T,scale=T)
head(wine)
resacp<-PCA(wine,quali.sup=c(1,2), scale.unit = TRUE,graph=FALSE)
fviz_mclust(resbic,what="BIC")
summary(resbic)
aux = data.frame(label=paste("Cl", resbic$classification, sep = ""), proba = apply(resbic$z, 1, max))
# Boxplot des probabilités a posteriori maximales
h1 = ggplot(aux,aes(x=label, y=proba))+ geom_boxplot()
# Visualisation du clustering
h2 = fviz_cluster(resbic, data = Data, ellipse.type="norm", geom = "point") +ggtitle("")+theme(legend.position = "none")
grid.arrange(h1,h2,ncol=2)
# Effectifs par classe
resICL<-mclustICL(wine[,-c(1,2)])
summary(resICL)
resICL<-Mclust(wine[,-c(1,2)], G=3, modelNames = "EEV")
aux = data.frame(label=paste("Cl", resICL$classification, sep = ""), proba = apply(resICL$z, 1, max))
# Boxplot des probabilités a posteriori maximales
h1 = ggplot(aux,aes(x=label, y=proba))+ geom_boxplot()
# Visualisation du clustering
h2 = fviz_cluster(resICL, data = Data, ellipse.type="norm", geom = "point") +ggtitle("")+theme(legend.position = "none")
grid.arrange(h1,h2,ncol=2)
# Effectifs par classe
zoo<-read.table("zoo-dataTP.txt",header=T,stringsAsFactors = TRUE)
for (j in 1:ncol(zoo))
zoo[,j]<-as.factor(zoo[,j])
summary(zoo)
dim(zoo)
res.mca<- MCA(zoo,ncp = 5, graph = FALSE)
fviz_mca_ind(res.mca)
# J indice des variables
# Data = jeu de données
# clust = clustering étudié
# output : graphe par variable dans J donnant la répartition des modalités de J par classe de clust
barplotClus <- function(clust, Data, J) {
aux.long.p <- heatm(clust, Data, J)$freq
# ux<-unique(aux.long.p$variable)
for (j in J) {
p <- ggplot(aux.long.p[which(aux.long.p$variable == colnames(Data)[j]), ],
aes(x = clust, y = perc, fill = value)) + geom_bar(stat = "identity")+
labs(fill = colnames(Data)[j])
print(p)
}
}
heatm <- function(clust, Data, J) {
library(dplyr)
Dataaux <- data.frame(id.s = c(1:nrow(Data)), Data)
aux <- cbind(Dataaux, clust)
aux.long <- melt(data.frame(lapply(aux, as.character)), stringsAsFactors = FALSE,
id = c("id.s", "clust"), factorsAsStrings = T)
# Effectifs
aux.long.q <- aux.long %>%
group_by(clust, variable, value) %>%
mutate(count = n_distinct(id.s)) %>%
distinct(clust, variable, value, count)
# avec fréquences
aux.long.p <- aux.long.q %>%
group_by(clust, variable) %>%
mutate(perc = count/sum(count)) %>%
arrange(clust)
Lev <- NULL
for (j in 1:ncol(Data)) Lev <- c(Lev, levels(Data[, j]))
Jaux <- NULL
for (j in 1:length(J)) {
Jaux <- c(Jaux, which(aux.long.p$variable == colnames(Data)[J[j]]))
}
gaux <- ggplot(aux.long.p[Jaux, ], aes(x = clust, y = value)) + geom_tile(aes(fill = perc)) +
scale_fill_gradient2(low = "white", mid = "blue", high = "red") + theme_minimal()
return(list(gaux = gaux, eff = aux.long.q, freq = aux.long.p))
}
aux = data.frame(label=paste("Cl", resBICdiag$classification, sep = ""), proba = apply(resBICdiag$z, 1, max))
library(knitr)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=FALSE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE,
class.source="badCode")
opts_knit$set(width=75)
## Pour faire le TP
library(mclust)
library(Rmixmod)
library(ggplot2)
library(gridExtra)
library(FactoMineR)
library(factoextra)
library(reshape2)
library(circlize)
library(viridis)
a<- 3
b<- 1
mu<-c(-a,0,a) # les moyennes \mu_k
sigma<-c(b,0.5,b) # les \sigma_k
prop<-c(0.2,0.3,0.5)
n<- 1000
Z<-rmultinom(n, 1, prop)
X<-data.frame(X=c(rnorm(sum(Z[1,]==1), mu[1], sigma[1]),
rnorm(sum(Z[2,]==1), mu[2], sigma[2]),
rnorm(sum(Z[3,]==1), mu[3], sigma[3])))
labeltrue<-c(rep(1,sum(Z[1,]==1)),rep(2,sum(Z[2,]==1)),rep(3,sum(Z[3,]==1)))
# vecteur des vrais labels
aux<-seq(-(a+4),a+4,0.01)
Y<-data.frame(x=aux,
y1=(prop[1]*dnorm(aux,mu[1],sigma[1])),
y2=(prop[2]*dnorm(aux,mu[2],sigma[2])),
y3=(prop[3]*dnorm(aux,mu[3],sigma[3])))
gvrai<-ggplot(X,aes(x=X))+
geom_histogram(aes(y = after_stat(density)),bins=100)+
geom_line(aes(x=x,y=y1),data=Y,col="red")+
geom_line(aes(x=x,y=y2),data=Y,col="blue")+
geom_line(aes(x=x,y=y3),data=Y,col="green")
gvrai
# A completer
res<-Mclust(X$X, G=3)
table(res$classification, labeltrue)
adjustedRandIndex(res$classification, labeltrue)
res$z
res$parameters
# A completer
# dans y_k <- \pi_k \times \phi(x; \mu_k,\sigma_k^2)
MelEstim<-data.frame(x=aux,
y1=(res$parameters$pro[1]*dnorm(aux,res$parameters$mean[1],res$parameters$variance$sigmasq[1])),
y2=(res$parameters$pro[2]*dnorm(aux,res$parameters$mean[2],res$parameters$variance$sigmasq[2])),
y3=(res$parameters$pro[3]*dnorm(aux,res$parameters$mean[3],res$parameters$variance$sigmasq[3])))
MelEstim<-data.frame(MelEstim,Somme=apply(MelEstim[,2:4],1,sum))
gMelEst<-ggplot(X,aes(x=X))+
geom_histogram(aes(y = after_stat(density)),bins=100)+
geom_line(aes(x=x,y=y1),data=MelEstim,col="red")+
geom_line(aes(x=x,y=y2),data=MelEstim,col="blue")+
geom_line(aes(x=x,y=y3),data=MelEstim,col="green")+
geom_line(aes(x=x,y=Somme),data=MelEstim,col="cyan",linetype = "dashed",size=1.5)
gMelEst
# dans p, les proba a posteriori d'appartenance t_{11},\ldots,t_{n1},t_{12},\ldots,t_{n3}
MelProba<-data.frame(x=rep(aux,3),
p= c(MelEstim$y1/(MelEstim$y1+MelEstim$y2+MelEstim$y3), MelEstim$y2/(MelEstim$y1+MelEstim$y2+MelEstim$y3), MelEstim$y3/(MelEstim$y1+MelEstim$y2+MelEstim$y3)),
class=as.factor(rep(c(1,2,3),each=length(aux))))
gprobapost<-ggplot(MelProba,aes(x=x,y=p,col=class))+geom_line()
gprobapost
df<-data.frame(lab=as.factor(apply(res$z,1,which.max)),probamax=apply(res$z,1,max))
gprobamax<-ggplot(df,aes(x=lab,y=probamax))+geom_boxplot()
grid.arrange(gvrai,gMelEst,gprobapost,gprobamax,ncol=2)
library(mclust)
data(Baudry_etal_2010_JCGS_examples)
Data<-ex4.1
ggplot(Data,aes(x=X1,y=X2))+geom_point()
# A COMPLETER
resBICdiag<-Mclust(Data, G=2:10, modelNames = c("EII", "VII", "EEI", "VEI", "EVI", "VVI"))
resBICdiag
fviz_mclust(resBICdiag,what="BIC")
summary(resBICdiag)
aux = data.frame(label=paste("Cl", resBICdiag$classification, sep = ""), proba = apply(resBICdiag$z, 1, max))
# Boxplot des probabilités a posteriori maximales
h1 = ggplot(aux,aes(x=label, y=proba))+ geom_boxplot()
# Visualisation du clustering
h2 = fviz_cluster(resBICdiag, data = Data, ellipse.type="norm", geom = "point") +ggtitle("")+theme(legend.position = "none")
grid.arrange(h1,h2,ncol=2)
# Effectifs par classe
resICL<-mclustICL(Data, G=2:10, modelNames = c("EII", "VII", "EEI", "VEI", "EVI", "VVI"))
summary(resICL)
resICL<-Mclust(Data, G=4, modelNames = "EVI")
aux = data.frame(label=paste("Cl", resICL$classification, sep = ""), proba = apply(resICL$z, 1, max))
# Boxplot des probabilités a posteriori maximales
h1 = ggplot(aux,aes(x=label, y=proba))+ geom_boxplot()
# Visualisation du clustering
h2 = fviz_cluster(resICL, data = Data, ellipse.type="norm", geom = "point") +ggtitle("")+theme(legend.position = "none")
grid.arrange(h1,h2,ncol=2)
# Effectifs par classe
resICL<-mclustICL(Data, G=2:10)
summary(resICL)
resICL<-Mclust(Data, G=6, modelNames = "EEV")
aux = data.frame(label=paste("Cl", resICL$classification, sep = ""), proba = apply(resICL$z, 1, max))
# Boxplot des probabilités a posteriori maximales
h1 = ggplot(aux,aes(x=label, y=proba))+ geom_boxplot()
# Visualisation du clustering
h2 = fviz_cluster(resICL, data = Data, ellipse.type="norm", geom = "point") +ggtitle("")+theme(legend.position = "none")
grid.arrange(h1,h2,ncol=2)
# Effectifs par classe
resacp<-PCA(wine,quali.sup=c(1,2), scale.unit = TRUE,graph=FALSE)
resbic = Mclust(wine[,-c(1,2)])
fviz_mclust(resbic,what="BIC")
summary(resbic)
help("mclustModelNames()")
help("mclustModelNames"
# A COMPLETER
resBICdiag<-Mclust(Data, G=2:10, modelNames = c("EII", "VII", "EEI", "VEI", "EVI", "VVI"))
help(mclustModelNames)
